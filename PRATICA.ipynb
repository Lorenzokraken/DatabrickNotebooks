{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c0095e",
   "metadata": {},
   "source": [
    "# ESERCIZIO 2 - PIPELINE DATABRICKS\n",
    "\n",
    "## OBIETTIVO\n",
    "Creare una pipeline personalizzata con i dataset di bike sharing, trasformazioni, join e schedulazione con timezone asiatico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owa3yf1tn2",
   "metadata": {},
   "source": [
    "# STEP 0: SETUP DATABRICKS\n",
    "- [ ] Accedere a **Databricks Workspace**\n",
    "- [ ] Andare su **Workspace** > **Create** > **Notebook**\n",
    "- [ ] Nome: `Esercizio_2_Pipeline`\n",
    "- [ ] Language: **Python**\n",
    "- [ ] Cluster: selezionare cluster attivo\n",
    "\n",
    "# STEP 1: PREPARAZIONE DATI\n",
    "\n",
    "## Bronze Layer\n",
    "```python\n",
    "# Lettura dati grezzi\n",
    "df_day = spark.read.csv(\"/databricks-datasets/bikeSharing/data-001/day.csv\", header=True, inferSchema=True)\n",
    "df_hour = spark.read.csv(\"/databricks-datasets/bikeSharing/data-001/hour.csv\", header=True, inferSchema=True)\n",
    "```\n",
    "\n",
    "## Silver Layer - Trasformazioni\n",
    "```python\n",
    "# PRIMA TABELLA: Classificare i giorni in base al numero di utenti registrati\n",
    "def classifica_giorno(utenti_registrati):\n",
    "    if utenti_registrati > 5000:\n",
    "        return \"Alto\"\n",
    "    elif utenti_registrati > 2000:\n",
    "        return \"Medio\"\n",
    "    else:\n",
    "        return \"Basso\"\n",
    "\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType\n",
    "classifica_udf = udf(classifica_giorno, StringType())\n",
    "df_day_clean = df_day.withColumn(\"livello_utilizzo\", classifica_udf(col(\"registered\")))\n",
    "\n",
    "# SECONDA TABELLA: Aggiungere un campo calcolato per l'ora della giornata\n",
    "from pyspark.sql.functions import concat, lpad\n",
    "df_hour_clean = df_hour.withColumn(\"data_ora\", concat(col(\"dteday\"), lpad(col(\"hr\"), 2, '0')))\n",
    "```\n",
    "\n",
    "## Gold Layer - Join finale\n",
    "```python\n",
    "# Creare un dataset finale che unisca i dati giornalieri con quelli orari\n",
    "df_finale = df_day_clean.join(df_hour_clean, \"dteday\", \"inner\")\n",
    "```\n",
    "\n",
    "# STEP 3: SALVATAGGIO SCHEMI\n",
    "```sql\n",
    "CREATE DATABASE IF NOT EXISTS bronze;\n",
    "CREATE DATABASE IF NOT EXISTS silver;  \n",
    "CREATE DATABASE IF NOT EXISTS gold;\n",
    "```\n",
    "\n",
    "```python\n",
    "# Salvare nelle tabelle\n",
    "df_day.write.mode(\"overwrite\").saveAsTable(\"bronze.bike_sharing_day_raw\")\n",
    "df_hour.write.mode(\"overwrite\").saveAsTable(\"bronze.bike_sharing_hour_raw\")\n",
    "df_day_clean.write.mode(\"overwrite\").saveAsTable(\"silver.bike_sharing_day_clean\")\n",
    "df_hour_clean.write.mode(\"overwrite\").saveAsTable(\"silver.bike_sharing_hour_clean\")\n",
    "df_finale.write.mode(\"overwrite\").saveAsTable(\"gold.bike_sharing_final\")\n",
    "```\n",
    "\n",
    "# STEP 3.1: CREAZIONE PIPELINE\n",
    "- [ ] Andare in **Delta Live Tables** > **Create Pipeline\n",
    "- [ ] Nome: `Bike_Sharing_Pipeline`\n",
    "- [ ] Source code: selezionare il notebook `Esercizio_2_Pipeline`\n",
    "- [ ] Destination: selezionare il catalogo e lo schema appropriati\n",
    "- [ ] Cluster mode: selezionare **Fixed size** o **Enhanced autoscaling**\n",
    "- [ ] Pipeline mode: **Triggered**\n",
    "- [ ] Cliccare su **Create**\n",
    "\n",
    "# STEP 4: CREAZIONE JOB\n",
    "- [ ] Andare in **Workflows** > **Create Job**\n",
    "- [ ] Nome: `Pipeline_Esercizio_2`\n",
    "- [ ] Task type: **Notebook**\n",
    "- [ ] Source: selezionare il notebook `Esercizio_2_Pipeline`\n",
    "- [ ] Cluster: selezionare cluster esistente\n",
    "\n",
    "# STEP 5: SCHEDULAZIONE ASIATICA\n",
    "- [ ] Schedule: **Scheduled**\n",
    "- [ ] Cron: `0 9 * * *` (ogni giorno ore 9:00)\n",
    "- [ ] Timezone: **Asia/Tokyo**\n",
    "\n",
    "# STEP 6: NOTIFICHE\n",
    "- [ ] Notifications > On Success: inserire email\n",
    "- [ ] Notifications > On Failure: inserire email\n",
    "- [ ] **Run Now** per testare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db2ab62",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- create catalog, schemas and volume\n",
    "CREATE CATALOG IF NOT EXISTS test_catalog;\n",
    "CREATE SCHEMA IF NOT EXISTS test_catalog.test_schema;\n",
    "CREATE VOLUME IF NOT EXISTS test_catalog.test_schema.test_volume;\n",
    "CREATE SCHEMA IF NOT EXISTS test_catalog.test_bronze_schema;\n",
    "CREATE SCHEMA IF NOT EXISTS test_catalog.test_silver_schema;\n",
    "CREATE SCHEMA IF NOT EXISTS test_catalog.test_gold_schema;"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}