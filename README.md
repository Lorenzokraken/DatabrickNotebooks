# ğŸš€ Guida Databricks/Spark

---

## ğŸ“– Come Usare Questa Guida

Questa cartella contiene appunti organizzati per imparare Databricks e Spark passo passo.

### ğŸ¯ Percorso di Apprendimento Consigliato

#### 1ï¸âƒ£ **Inizia qui: Capire i Big Data**
ğŸ“‚ [SPARK/1) Introduzione ai Big Datas.ipynb](SPARK/1)%20Introduzione%20ai%20Big%20Datas.ipynb)
- Cos'Ã¨ un Big Data problem
- Quando serve Spark invece di Pandas
- Cluster, scalabilitÃ , cloud
- **Tempo**: 15 minuti

#### 2ï¸âƒ£ **Da Pandas a Spark: Il Ponte**
ğŸ“‚ [DOCS/PANDAS_TO_SPARK.ipynb](DOCS/PANDAS_TO_SPARK.ipynb)
- **INIZIA SEMPRE DA QUI SE CONOSCI PANDAS** â­
- Equivalenze Pandas â†” Spark
- Esempi pratici affiancati
- Errori comuni da evitare
- **Tempo**: 30 minuti

#### 3ï¸âƒ£ **ETL in Databricks: Pratica Base**
ğŸ“‚ [LEZIONI/LEZIONE 1 APPUNTI.IPYNB](LEZIONI/LEZIONE%201%20APPUNTI.IPYNB)
- Extract-Transform-Load completo
- Leggere da file e tabelle
- Trasformazioni, aggregazioni, join
- Salvare risultati
- Pipeline ETL completa
- **Tempo**: 45 minuti

#### 4ï¸âƒ£ **Cheatsheet: Riferimento Rapido**
ğŸ“‚ [DOCS/databricks_cheatsheet.ipynb](DOCS/databricks_cheatsheet.ipynb)
- Comandi ordinati per complessitÃ 
- Snippet pronti all'uso
- Template per esercizi
- **Uso**: Tieni aperto mentre lavori

#### 5ï¸âƒ£ **Architettura Lakehouse** (Opzionale - Teoria)
ğŸ“‚ [LEZIONI/LEZIONE 2 APPUNTI.IPYNB](LEZIONI/LEZIONE%202%20APPUNTI.IPYNB)
- Cos'Ã¨ l'architettura Lakehouse
- Unity Catalog
- Governance e best practices
- **Tempo**: 20 minuti

#### 6ï¸âƒ£ **Integrazione Cloud** (Opzionale - Avanzato)
ğŸ“‚ [LEZIONI/LEZIONE 3 APPUNTI.IPYNB](LEZIONI/LEZIONE%203%20APPUNTI.IPYNB)
- Azure Data Lake Storage (ADLS)
- Mounting cloud storage
- Volumi e cataloghi
- **Tempo**: 30 minuti

#### 7ï¸âƒ£ **Esercizi Pratici**
ğŸ“‚ [PRATICA.ipynb](PRATICA.ipynb) e [PRATICA 2.ipynb](PRATICA%202.ipynb)
- Delta Live Tables
- Pipeline complete
- Esempi reali
- **Fai dopo aver completato i punti 1-4**

---

## ğŸ“ Percorso Veloce (2 Ore)

Se hai poco tempo, segui questo percorso minimo:

1. âš¡ [PANDAS_TO_SPARK.ipynb](DOCS/PANDAS_TO_SPARK.ipynb) - **30 min**
2. âš¡ [LEZIONE 1 APPUNTI.IPYNB](LEZIONI/LEZIONE%201%20APPUNTI.IPYNB) - **45 min**
3. âš¡ [databricks_cheatsheet.ipynb](DOCS/databricks_cheatsheet.ipynb) - **15 min lettura**
4. âš¡ [PRATICA.ipynb](PRATICA.ipynb) - **30 min esercizio**

Dopo questo sei pronta per iniziare a lavorare!

---

## ğŸ’¡ Concetti Chiave da Ricordare

### Pandas vs Spark
```python
# âŒ Pandas: Tutto in RAM su 1 macchina (limite ~10GB)
df = pd.read_csv("data.csv")
df.groupby('col').sum()

# âœ… Spark: Distribuito su cluster (scala a TB/PB)
df = spark.read.csv("data.csv", header=True, inferSchema=True)
df.groupBy('col').sum().show()
```

### Quando usare cosa?
- **Pandas**: Dataset < 10GB, prototipazione veloce, notebook locali
- **Spark**: Dataset > 10GB, produzione, scalabilitÃ , Big Data

### Regola d'oro
â›” **MAI convertire a Pandas per operazioni su grandi dataset:**
```python
# âŒ SBAGLIATO
df.toPandas().groupby('col').sum()  # Porta tutto in memoria!

# âœ… CORRETTO
df.groupBy('col').sum()  # Rimane distribuito
```

---

## ğŸ› ï¸ Setup Databricks

### Community Edition (Gratis)
1. Vai su https://community.cloud.databricks.com/
2. Registrati gratuitamente
3. Crea un cluster (single-node va bene per imparare)
4. Carica questi notebook

### Workspace Aziendale
Se hai accesso a Azure Databricks:
1. Importa questa cartella nel workspace
2. Crea un cluster (o usa uno esistente)
3. Inizia dal percorso consigliato

---

## ğŸ“š Struttura Cartella

```
Databricks/
â”‚
â”œâ”€â”€ DOCS/                          # Riferimenti e guide
â”‚   â”œâ”€â”€ PANDAS_TO_SPARK.ipynb     â­ INIZIA QUI se conosci Pandas
â”‚   â”œâ”€â”€ databricks_cheatsheet.ipynb
â”‚   â””â”€â”€ code_docs_alternative.ipynb
â”‚
â”œâ”€â”€ LEZIONI/                       # Teoria ed esempi
â”‚   â”œâ”€â”€ LEZIONE 1 APPUNTI.IPYNB   # ETL Base
â”‚   â”œâ”€â”€ LEZIONE 2 APPUNTI.IPYNB   # Architettura Lakehouse
â”‚   â””â”€â”€ LEZIONE 3 APPUNTI.IPYNB   # Integrazione Cloud
â”‚
â”œâ”€â”€ SPARK/                         # Concetti Big Data
â”‚   â”œâ”€â”€ 1) Introduzione ai Big Datas.ipynb
â”‚   â””â”€â”€ 2) Progetti di Big Data.ipynb
â”‚
â”œâ”€â”€ PRATICA.ipynb                  # Esercizi pratici
â”œâ”€â”€ PRATICA 2.ipynb                # Pipeline avanzate
â””â”€â”€ README.md                      # Questa guida
```

---

## ğŸ¯ Obiettivi di Apprendimento

Dopo aver completato questo percorso saprai:

âœ… Leggere dati da file e tabelle in Spark  
âœ… Trasformare dati con filter, select, withColumn  
âœ… Fare aggregazioni con groupBy  
âœ… Join tra dataset  
âœ… Salvare risultati come tabelle Delta  
âœ… Creare pipeline ETL complete  
âœ… Evitare errori comuni (toPandas, iterazioni, ecc.)  
âœ… Usare Unity Catalog per organizzare dati  
âœ… Differenza tra Batch e Streaming  

---

## ğŸ†˜ Risorse Esterne

- **Databricks Academy**: https://academy.databricks.com/ (corsi gratis)
- **PySpark Documentation**: https://spark.apache.org/docs/latest/api/python/
- **Delta Lake**: https://docs.delta.io/
- **Community Forums**: https://community.databricks.com/

---

## ğŸ’¬ Suggerimenti

### Per imparare velocemente:
1. **Non leggere tutto**: Segui il percorso consigliato
2. **Pratica subito**: Dopo ogni concetto, prova su Databricks
3. **Usa il cheatsheet**: Copialo e modificalo per i tuoi casi
4. **Paragona con Pandas**: Ogni volta che vedi Spark, pensa "come lo farei in Pandas?"

### Per ricordare:
- Spark Ã¨ **lazy**: pianifica ma esegue solo con `.show()`, `.count()`, `.write()`
- Spark Ã¨ **immutabile**: ogni trasformazione crea un nuovo DataFrame
- **Cache** se riusi lo stesso DataFrame piÃ¹ volte: `.cache()`

### Errori comuni:
```python
# âŒ Non iterare riga per riga
for row in df.collect():  # Lento!
    process(row)

# âœ… Usa trasformazioni vettoriali
df.withColumn('new', process_udf(col('old')))
```

---

## âœ¨ Buono Studio!

Se hai domande o trovi errori negli appunti, contatta chi ti ha passato questi materiali.

**Ricorda**: Spark non Ã¨ complicato, Ã¨ solo diverso da Pandas. Una volta capito il mindset distribuito, tutto diventa naturale! ğŸš€
